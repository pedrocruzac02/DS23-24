{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array, ndarray\n",
    "from matplotlib.pyplot import subplots, figure, savefig, show\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from library.dslabs_functions import (\n",
    "    CLASS_EVAL_METRICS,\n",
    "    DELTA_IMPROVE,\n",
    "    read_train_test_from_files,\n",
    ")\n",
    "from library.dslabs_functions import HEIGHT, plot_evaluation_results, plot_multiline_chart\n",
    "\n",
    "\n",
    "def random_forests_study(\n",
    "    trnX: ndarray,\n",
    "    trnY: array,\n",
    "    tstX: ndarray,\n",
    "    tstY: array,\n",
    "    nr_max_trees: int = 2500,\n",
    "    lag: int = 500,\n",
    "    metric: str = \"accuracy\",\n",
    ") -> tuple[RandomForestClassifier | None, dict]:\n",
    "    n_estimators: list[int] = [100] + [i for i in range(500, nr_max_trees + 1, lag)]\n",
    "    max_depths: list[int] = [2, 5, 7]\n",
    "    max_features: list[float] = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "\n",
    "    best_model: RandomForestClassifier | None = None\n",
    "    best_params: dict = {\"name\": \"RF\", \"metric\": metric, \"params\": ()}\n",
    "    best_performance: float = 0.0\n",
    "\n",
    "    values: dict = {}\n",
    "\n",
    "    cols: int = len(max_depths)\n",
    "    _, axs = subplots(1, cols, figsize=(cols * HEIGHT, HEIGHT), squeeze=False)\n",
    "    for i in range(len(max_depths)):\n",
    "        d: int = max_depths[i]\n",
    "        values = {}\n",
    "        for f in max_features:\n",
    "            y_tst_values: list[float] = []\n",
    "            for n in n_estimators:\n",
    "                clf = RandomForestClassifier(\n",
    "                    n_estimators=n, max_depth=d, max_features=f\n",
    "                )\n",
    "                clf.fit(trnX, trnY)\n",
    "                prdY: array = clf.predict(tstX)\n",
    "                eval: float = CLASS_EVAL_METRICS[metric](tstY, prdY)\n",
    "                y_tst_values.append(eval)\n",
    "                if eval - best_performance > DELTA_IMPROVE:\n",
    "                    best_performance = eval\n",
    "                    best_params[\"params\"] = (d, f, n)\n",
    "                    best_model = clf\n",
    "                print(f'RF d={d} f={f} n={n}')\n",
    "            values[f] = y_tst_values\n",
    "        plot_multiline_chart(\n",
    "            n_estimators,\n",
    "            values,\n",
    "            ax=axs[0, i],\n",
    "            title=f\"Random Forests with max_depth={d}\",\n",
    "            xlabel=\"nr estimators\",\n",
    "            ylabel=metric,\n",
    "            percentage=True,\n",
    "        )\n",
    "    print(\n",
    "        f'RF best for {best_params[\"params\"][2]} trees (d={best_params[\"params\"][0]} and f={best_params[\"params\"][1]})'\n",
    "    )\n",
    "    return best_model, best_params\n",
    "\n",
    "\n",
    "file_tag = \"class_pos_covid\"\n",
    "train_filename = \"class_pos_covid_train.csv\"\n",
    "test_filename = \"class_pos_covid_test.csv\"\n",
    "target = \"CovidPos\"\n",
    "eval_metric = \"accuracy\"\n",
    "\n",
    "trnX, tstX, trnY, tstY, labels, vars = read_train_test_from_files(\n",
    "    train_filename, test_filename, target\n",
    ")\n",
    "print(f\"Train#={len(trnX)} Test#={len(tstX)}\")\n",
    "print(f\"Labels={labels}\")\n",
    "\n",
    "figure()\n",
    "best_model, params = random_forests_study(\n",
    "    trnX,\n",
    "    trnY,\n",
    "    tstX,\n",
    "    tstY,\n",
    "    nr_max_trees=1000,\n",
    "    lag=250,\n",
    "    metric=eval_metric,\n",
    ")\n",
    "#savefig(f\"images/{file_tag}_rf_{eval_metric}_study.png\")\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prd_trn: array = best_model.predict(trnX)\n",
    "prd_tst: array = best_model.predict(tstX)\n",
    "figure()\n",
    "plot_evaluation_results(params, trnY, prd_trn, tstY, prd_tst, labels)\n",
    "#savefig(f'images/{file_tag}_rf_{params[\"name\"]}_best_{params[\"metric\"]}_eval.png')\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import std, argsort\n",
    "from library.dslabs_functions import plot_horizontal_bar_chart\n",
    "\n",
    "stdevs: list[float] = list(\n",
    "    std([tree.feature_importances_ for tree in best_model.estimators_], axis=0)\n",
    ")\n",
    "importances = best_model.feature_importances_\n",
    "indices: list[int] = argsort(importances)[::-1]\n",
    "elems: list[str] = []\n",
    "imp_values: list[float] = []\n",
    "for f in range(len(vars)):\n",
    "    elems += [vars[indices[f]]]\n",
    "    imp_values.append(importances[indices[f]])\n",
    "    print(f\"{f+1}. {elems[f]} ({importances[indices[f]]})\")\n",
    "\n",
    "figure()\n",
    "plot_horizontal_bar_chart(\n",
    "    elems,\n",
    "    imp_values,\n",
    "    error=stdevs,\n",
    "    title=\"RF variables importance\",\n",
    "    xlabel=\"importance\",\n",
    "    ylabel=\"variables\",\n",
    "    percentage=True,\n",
    ")\n",
    "#savefig(f\"images/{file_tag}_rf_{eval_metric}_vars_ranking.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_max: int = params[\"params\"][0]\n",
    "feat: float = params[\"params\"][1]\n",
    "nr_estimators: list[int] = [i for i in range(2, 2501, 500)]\n",
    "\n",
    "y_tst_values: list[float] = []\n",
    "y_trn_values: list[float] = []\n",
    "acc_metric: str = \"accuracy\"\n",
    "\n",
    "for n in nr_estimators:\n",
    "    clf = RandomForestClassifier(n_estimators=n, max_depth=d_max, max_features=feat)\n",
    "    clf.fit(trnX, trnY)\n",
    "    prd_tst_Y: array = clf.predict(tstX)\n",
    "    prd_trn_Y: array = clf.predict(trnX)\n",
    "    y_tst_values.append(CLASS_EVAL_METRICS[acc_metric](tstY, prd_tst_Y))\n",
    "    y_trn_values.append(CLASS_EVAL_METRICS[acc_metric](trnY, prd_trn_Y))\n",
    "\n",
    "figure()\n",
    "plot_multiline_chart(\n",
    "    nr_estimators,\n",
    "    {\"Train\": y_trn_values, \"Test\": y_tst_values},\n",
    "    title=f\"RF overfitting study for d={d_max} and f={feat}\",\n",
    "    xlabel=\"nr_estimators\",\n",
    "    ylabel=str(eval_metric),\n",
    "    percentage=True,\n",
    ")\n",
    "#savefig(f\"images/{file_tag}_rf_{eval_metric}_overfitting.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from numpy import array, ndarray\n",
    "from matplotlib.pyplot import subplots, figure, savefig, show\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from library.dslabs_functions import (\n",
    "    CLASS_EVAL_METRICS,\n",
    "    DELTA_IMPROVE,\n",
    "    read_train_test_from_files,\n",
    ")\n",
    "from library.dslabs_functions import HEIGHT, plot_evaluation_results, plot_multiline_chart\n",
    "\n",
    "\n",
    "def mlp_study(\n",
    "    trnX: ndarray,\n",
    "    trnY: array,\n",
    "    tstX: ndarray,\n",
    "    tstY: array,\n",
    "    nr_max_iterations: int = 2500,\n",
    "    lag: int = 500,\n",
    "    metric: str = \"accuracy\",\n",
    ") -> tuple[MLPClassifier | None, dict]:\n",
    "    nr_iterations: list[int] = [lag] + [\n",
    "        i for i in range(2 * lag, nr_max_iterations + 1, lag)\n",
    "    ]\n",
    "\n",
    "    lr_types: list[Literal[\"constant\", \"invscaling\", \"adaptive\"]] = [\n",
    "        \"constant\",\n",
    "        \"invscaling\",\n",
    "        \"adaptive\",\n",
    "    ]  # only used if optimizer='sgd'\n",
    "    learning_rates: list[float] = [0.5, 0.05, 0.005, 0.0005]\n",
    "\n",
    "    best_model: MLPClassifier | None = None\n",
    "    best_params: dict = {\"name\": \"MLP\", \"metric\": metric, \"params\": ()}\n",
    "    best_performance: float = 0.0\n",
    "\n",
    "    values: dict = {}\n",
    "    _, axs = subplots(\n",
    "        1, len(lr_types), figsize=(len(lr_types) * HEIGHT, HEIGHT), squeeze=False\n",
    "    )\n",
    "\n",
    "    for i in range(len(lr_types)):\n",
    "        type: str = lr_types[i]\n",
    "        values = {}\n",
    "        for lr in learning_rates:\n",
    "            warm_start: bool = False\n",
    "            y_tst_values: list[float] = []\n",
    "            for j in range(len(nr_iterations)):\n",
    "                clf = MLPClassifier(\n",
    "                    learning_rate=type,\n",
    "                    learning_rate_init=lr,\n",
    "                    max_iter=lag,\n",
    "                    warm_start=warm_start,\n",
    "                    activation=\"logistic\",\n",
    "                    solver=\"sgd\",\n",
    "                    verbose=False,\n",
    "                )\n",
    "                clf.fit(trnX, trnY)\n",
    "                prdY: array = clf.predict(tstX)\n",
    "                eval: float = CLASS_EVAL_METRICS[metric](tstY, prdY)\n",
    "                y_tst_values.append(eval)\n",
    "                warm_start = True\n",
    "                if eval - best_performance > DELTA_IMPROVE:\n",
    "                    best_performance = eval\n",
    "                    best_params[\"params\"] = (type, lr, nr_iterations[j])\n",
    "                    best_model = clf\n",
    "                print(f'MLP lr_type={type} lr={lr} n={nr_iterations[j]}')\n",
    "            values[lr] = y_tst_values\n",
    "        plot_multiline_chart(\n",
    "            nr_iterations,\n",
    "            values,\n",
    "            ax=axs[0, i],\n",
    "            title=f\"MLP with {type}\",\n",
    "            xlabel=\"nr iterations\",\n",
    "            ylabel=metric,\n",
    "            percentage=True,\n",
    "        )\n",
    "    print(\n",
    "        f'MLP best for {best_params[\"params\"][2]} iterations (lr_type={best_params[\"params\"][0]} and lr={best_params[\"params\"][1]}'\n",
    "    )\n",
    "\n",
    "    return best_model, best_params\n",
    "\n",
    "\n",
    "file_tag = \"class_pos_covid\"\n",
    "train_filename = \"class_pos_covid_train.csv\"\n",
    "test_filename = \"class_pos_covid_test.csv\"\n",
    "target = \"CovidPos\"\n",
    "eval_metric = \"accuracy\"\n",
    "\n",
    "trnX, tstX, trnY, tstY, labels, vars = read_train_test_from_files(\n",
    "    train_filename, test_filename, target\n",
    ")\n",
    "print(f\"Train#={len(trnX)} Test#={len(tstX)}\")\n",
    "print(f\"Labels={labels}\")\n",
    "\n",
    "figure()\n",
    "best_model, params = mlp_study(\n",
    "    trnX,\n",
    "    trnY,\n",
    "    tstX,\n",
    "    tstY,\n",
    "    nr_max_iterations=1000,\n",
    "    lag=250,\n",
    "    metric=eval_metric,\n",
    ")\n",
    "#savefig(f\"images/{file_tag}_mlp_{eval_metric}_study.png\")\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prd_trn: array = best_model.predict(trnX)\n",
    "prd_tst: array = best_model.predict(tstX)\n",
    "figure()\n",
    "plot_evaluation_results(params, trnY, prd_trn, tstY, prd_tst, labels)\n",
    "#savefig(f'images/{file_tag}_mlp_{params[\"name\"]}_best_{params[\"metric\"]}_eval.png')\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_type: Literal[\"constant\", \"invscaling\", \"adaptive\"] = params[\"params\"][0]\n",
    "lr: float = params[\"params\"][1]\n",
    "nr_iterations: list[int] = [i for i in range(100, 1001, 100)]\n",
    "\n",
    "y_tst_values: list[float] = []\n",
    "y_trn_values: list[float] = []\n",
    "acc_metric = \"accuracy\"\n",
    "\n",
    "warm_start: bool = False\n",
    "for n in nr_iterations:\n",
    "    clf = MLPClassifier(\n",
    "        warm_start=warm_start,\n",
    "        learning_rate=lr_type,\n",
    "        learning_rate_init=lr,\n",
    "        max_iter=n,\n",
    "        activation=\"logistic\",\n",
    "        solver=\"sgd\",\n",
    "        verbose=False,\n",
    "    )\n",
    "    clf.fit(trnX, trnY)\n",
    "    prd_tst_Y: array = clf.predict(tstX)\n",
    "    prd_trn_Y: array = clf.predict(trnX)\n",
    "    y_tst_values.append(CLASS_EVAL_METRICS[acc_metric](tstY, prd_tst_Y))\n",
    "    y_trn_values.append(CLASS_EVAL_METRICS[acc_metric](trnY, prd_trn_Y))\n",
    "    warm_start = True\n",
    "\n",
    "figure()\n",
    "plot_multiline_chart(\n",
    "    nr_iterations,\n",
    "    {\"Train\": y_trn_values, \"Test\": y_tst_values},\n",
    "    title=f\"MLP overfitting study for lr_type={lr_type} and lr={lr}\",\n",
    "    xlabel=\"nr_iterations\",\n",
    "    ylabel=str(eval_metric),\n",
    "    percentage=True,\n",
    ")\n",
    "#savefig(f\"images/{file_tag}_mlp_{eval_metric}_overfitting.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array, ndarray\n",
    "from matplotlib.pyplot import subplots, figure, savefig, show\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from library.dslabs_functions import (\n",
    "    CLASS_EVAL_METRICS,\n",
    "    DELTA_IMPROVE,\n",
    "    read_train_test_from_files,\n",
    ")\n",
    "from library.dslabs_functions import HEIGHT, plot_evaluation_results, plot_multiline_chart\n",
    "\n",
    "\n",
    "def gradient_boosting_study(\n",
    "    trnX: ndarray,\n",
    "    trnY: array,\n",
    "    tstX: ndarray,\n",
    "    tstY: array,\n",
    "    nr_max_trees: int = 2500,\n",
    "    lag: int = 500,\n",
    "    metric: str = \"accuracy\",\n",
    ") -> tuple[GradientBoostingClassifier | None, dict]:\n",
    "    n_estimators: list[int] = [100] + [i for i in range(500, nr_max_trees + 1, lag)]\n",
    "    max_depths: list[int] = [2, 5, 7]\n",
    "    learning_rates: list[float] = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "\n",
    "    best_model: GradientBoostingClassifier | None = None\n",
    "    best_params: dict = {\"name\": \"GB\", \"metric\": metric, \"params\": ()}\n",
    "    best_performance: float = 0.0\n",
    "\n",
    "    values: dict = {}\n",
    "    cols: int = len(max_depths)\n",
    "    _, axs = subplots(1, cols, figsize=(cols * HEIGHT, HEIGHT), squeeze=False)\n",
    "    for i in range(len(max_depths)):\n",
    "        d: int = max_depths[i]\n",
    "        values = {}\n",
    "        for lr in learning_rates:\n",
    "            y_tst_values: list[float] = []\n",
    "            for n in n_estimators:\n",
    "                clf = GradientBoostingClassifier(\n",
    "                    n_estimators=n, max_depth=d, learning_rate=lr\n",
    "                )\n",
    "                clf.fit(trnX, trnY)\n",
    "                prdY: array = clf.predict(tstX)\n",
    "                eval: float = CLASS_EVAL_METRICS[metric](tstY, prdY)\n",
    "                y_tst_values.append(eval)\n",
    "                if eval - best_performance > DELTA_IMPROVE:\n",
    "                    best_performance = eval\n",
    "                    best_params[\"params\"] = (d, lr, n)\n",
    "                    best_model = clf\n",
    "                print(f'GB d={d} lr={lr} n={n}')\n",
    "            values[lr] = y_tst_values\n",
    "        plot_multiline_chart(\n",
    "            n_estimators,\n",
    "            values,\n",
    "            ax=axs[0, i],\n",
    "            title=f\"Gradient Boosting with max_depth={d}\",\n",
    "            xlabel=\"nr estimators\",\n",
    "            ylabel=metric,\n",
    "            percentage=True,\n",
    "        )\n",
    "    print(\n",
    "        f'GB best for {best_params[\"params\"][2]} trees (d={best_params[\"params\"][0]} and lr={best_params[\"params\"][1]}'\n",
    "    )\n",
    "\n",
    "    return best_model, best_params\n",
    "\n",
    "\n",
    "file_tag = \"class_pos_covid\"\n",
    "train_filename = \"class_pos_covid_train.csv\"\n",
    "test_filename = \"class_pos_covid_test.csv\"\n",
    "target = \"CovidPos\"\n",
    "eval_metric = \"accuracy\"\n",
    "\n",
    "trnX, tstX, trnY, tstY, labels, vars = read_train_test_from_files(\n",
    "    train_filename, test_filename, target\n",
    ")\n",
    "print(f\"Train#={len(trnX)} Test#={len(tstX)}\")\n",
    "print(f\"Labels={labels}\")\n",
    "\n",
    "figure()\n",
    "best_model, params = gradient_boosting_study(\n",
    "    trnX,\n",
    "    trnY,\n",
    "    tstX,\n",
    "    tstY,\n",
    "    nr_max_trees=1000,\n",
    "    lag=250,\n",
    "    metric=eval_metric,\n",
    ")\n",
    "#savefig(f\"images/{file_tag}_gb_{eval_metric}_study.png\")\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prd_trn: array = best_model.predict(trnX)\n",
    "prd_tst: array = best_model.predict(tstX)\n",
    "figure()\n",
    "plot_evaluation_results(params, trnY, prd_trn, tstY, prd_tst, labels)\n",
    "#savefig(f'images/{file_tag}_gb_{params[\"name\"]}_best_{params[\"metric\"]}_eval.png')\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import std, argsort\n",
    "from library.dslabs_functions import plot_horizontal_bar_chart\n",
    "\n",
    "trees_importances: list[float] = []\n",
    "for lst_trees in best_model.estimators_:\n",
    "    for tree in lst_trees:\n",
    "        trees_importances.append(tree.feature_importances_)\n",
    "\n",
    "stdevs: list[float] = list(std(trees_importances, axis=0))\n",
    "importances = best_model.feature_importances_\n",
    "indices: list[int] = argsort(importances)[::-1]\n",
    "elems: list[str] = []\n",
    "imp_values: list[float] = []\n",
    "for f in range(len(vars)):\n",
    "    elems += [vars[indices[f]]]\n",
    "    imp_values.append(importances[indices[f]])\n",
    "    print(f\"{f+1}. {elems[f]} ({importances[indices[f]]})\")\n",
    "\n",
    "figure()\n",
    "plot_horizontal_bar_chart(\n",
    "    elems,\n",
    "    imp_values,\n",
    "    error=stdevs,\n",
    "    title=\"GB variables importance\",\n",
    "    xlabel=\"importance\",\n",
    "    ylabel=\"variables\",\n",
    "    percentage=True,\n",
    ")\n",
    "#savefig(f\"images/{file_tag}_gb_{eval_metric}_vars_ranking.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_max: int = params[\"params\"][0]\n",
    "lr: float = params[\"params\"][1]\n",
    "nr_estimators: list[int] = [i for i in range(2, 2501, 500)]\n",
    "\n",
    "y_tst_values: list[float] = []\n",
    "y_trn_values: list[float] = []\n",
    "acc_metric: str = \"accuracy\"\n",
    "\n",
    "for n in nr_estimators:\n",
    "    clf = GradientBoostingClassifier(n_estimators=n, max_depth=d_max, learning_rate=lr)\n",
    "    clf.fit(trnX, trnY)\n",
    "    prd_tst_Y: array = clf.predict(tstX)\n",
    "    prd_trn_Y: array = clf.predict(trnX)\n",
    "    y_tst_values.append(CLASS_EVAL_METRICS[acc_metric](tstY, prd_tst_Y))\n",
    "    y_trn_values.append(CLASS_EVAL_METRICS[acc_metric](trnY, prd_trn_Y))\n",
    "\n",
    "figure()\n",
    "plot_multiline_chart(\n",
    "    nr_estimators,\n",
    "    {\"Train\": y_trn_values, \"Test\": y_tst_values},\n",
    "    title=f\"GB overfitting study for d={d_max} and lr={lr}\",\n",
    "    xlabel=\"nr_estimators\",\n",
    "    ylabel=str(eval_metric),\n",
    "    percentage=True,\n",
    ")\n",
    "#savefig(f\"images/{file_tag}_gb_{eval_metric}_overfitting.png\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
