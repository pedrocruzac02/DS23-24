{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(380932, 40)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import read_csv, DataFrame\n",
    "\n",
    "filename = \"dataset/class_pos_covid.csv\"\n",
    "file_tag = \"class_pos_covid\"\n",
    "data: DataFrame = read_csv(filename, na_values=\"\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Dimensionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from library.dslabs_functions import get_variable_types\n",
    "\n",
    "variable_types: dict[str, list] = get_variable_types(data)\n",
    "print(variable_types)\n",
    "counts: dict[str, int] = {}\n",
    "for tp in variable_types.keys():\n",
    "    counts[tp] = len(variable_types[tp])\n",
    "\n",
    "figure(figsize=(4, 2))\n",
    "plot_bar_chart(\n",
    "    list(counts.keys()), list(counts.values()), title=\"Nr of variables per type\"\n",
    ")\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv: dict[str, int] = {}\n",
    "total = 0\n",
    "for var in data.columns:\n",
    "    nr: int = data[var].isna().sum()\n",
    "    total += nr\n",
    "    if nr > 0:\n",
    "        mv[var] = nr\n",
    "\n",
    "figure(figsize=(16, 8))\n",
    "plot_bar_chart(\n",
    "    list(mv.keys()),\n",
    "    list(mv.values()),\n",
    "    title=\"Nr of missing values per variable (Total = \" + str(total) + \" )\",\n",
    "    xlabel=\"variables\",\n",
    "    ylabel=\"nr missing values\",\n",
    ")\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Series\n",
    "from library.dslabs_functions import plot_bar_chart\n",
    "from library.dslabs_functions import define_grid, HEIGHT\n",
    "from matplotlib.pyplot import savefig, show, subplots\n",
    "\n",
    "symbolic: list[str] = variable_types[\"symbolic\"] + variable_types[\"binary\"]\n",
    "if [] != symbolic:\n",
    "    rows, cols = define_grid(len(symbolic))\n",
    "    fig, axs = subplots(\n",
    "        rows, cols, figsize=(cols * HEIGHT, rows * HEIGHT + 20), squeeze=False\n",
    "    )\n",
    "    i, j = 0, 0\n",
    "    for n in range(len(symbolic)):\n",
    "        counts: Series = data[symbolic[n]].value_counts()\n",
    "        plot_bar_chart(\n",
    "            counts.index.to_list(),\n",
    "            counts.to_list(),\n",
    "            ax=axs[i, j],\n",
    "            title=\"Histogram for %s\" % symbolic[n],\n",
    "            xlabel=symbolic[n],\n",
    "            ylabel=\"nr records\",\n",
    "            percentage=False,\n",
    "        )\n",
    "        i, j = (i + 1, 0) if (n + 1) % cols == 0 else (i, j + 1)\n",
    "    show()\n",
    "else:\n",
    "    print(\"There are no symbolic variables.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import savefig, show\n",
    "from library.dslabs_functions import get_variable_types\n",
    "\n",
    "numeric: list[str] = variables_types[\"numeric\"]\n",
    "figure(figsize=(8, 12))\n",
    "variables_types: dict[str, list] = get_variable_types(data)\n",
    "numeric: list[str] = variables_types[\"numeric\"]\n",
    "if [] != numeric:\n",
    "    data[numeric].boxplot(rot=45)\n",
    "    show()\n",
    "else:\n",
    "    print(\"There are no numeric variables.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import ndarray\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib.pyplot import savefig, show, subplots\n",
    "from library.dslabs_functions import define_grid, HEIGHT\n",
    "\n",
    "if [] != numeric:\n",
    "    rows: int\n",
    "    cols: int\n",
    "    rows, cols = define_grid(len(numeric))\n",
    "    fig: Figure\n",
    "    axs: ndarray\n",
    "    fig, axs = subplots(\n",
    "        rows, cols, figsize=(cols * HEIGHT, rows * HEIGHT), squeeze=False\n",
    "    )\n",
    "    i, j = 0, 0\n",
    "    for n in range(len(numeric)):\n",
    "        axs[i, j].set_title(\"Boxplot for %s\" % numeric[n])\n",
    "        axs[i, j].boxplot(data[numeric[n]].dropna().values)\n",
    "        i, j = (i + 1, 0) if (n + 1) % cols == 0 else (i, j + 1)\n",
    "    #savefig(f\"images/{file_tag}_single_boxplots.png\")\n",
    "    show()\n",
    "else:\n",
    "    print(\"There are no numeric variables.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Series\n",
    "from matplotlib.pyplot import figure, savefig, show\n",
    "from library.dslabs_functions import plot_multibar_chart\n",
    "\n",
    "NR_STDEV: int = 2\n",
    "IQR_FACTOR: float = 1.5\n",
    "\n",
    "def determine_outlier_thresholds_for_var(\n",
    "    summary5: Series, std_based: bool = True, threshold: float = NR_STDEV\n",
    ") -> tuple[float, float]:\n",
    "    top: float = 0\n",
    "    bottom: float = 0\n",
    "    if std_based:\n",
    "        std: float = threshold * summary5[\"std\"]\n",
    "        top = summary5[\"mean\"] + std\n",
    "        bottom = summary5[\"mean\"] - std\n",
    "    else:\n",
    "        iqr: float = threshold * (summary5[\"75%\"] - summary5[\"25%\"])\n",
    "        top = summary5[\"75%\"] + iqr\n",
    "        bottom = summary5[\"25%\"] - iqr\n",
    "\n",
    "    return top, bottom\n",
    "\n",
    "\n",
    "def count_outliers(\n",
    "    data: DataFrame,\n",
    "    numeric: list[str],\n",
    "    nrstdev: int = NR_STDEV,\n",
    "    iqrfactor: float = IQR_FACTOR,\n",
    ") -> dict:\n",
    "    outliers_iqr: list = []\n",
    "    outliers_stdev: list = []\n",
    "    summary5: DataFrame = data[numeric].describe()\n",
    "\n",
    "    for var in numeric:\n",
    "        top: float\n",
    "        bottom: float\n",
    "        top, bottom = determine_outlier_thresholds_for_var(\n",
    "            summary5[var], std_based=True, threshold=nrstdev\n",
    "        )\n",
    "        outliers_stdev += [\n",
    "            data[data[var] > top].count()[var] + data[data[var] < bottom].count()[var]\n",
    "        ]\n",
    "\n",
    "        top, bottom = determine_outlier_thresholds_for_var(\n",
    "            summary5[var], std_based=False, threshold=iqrfactor\n",
    "        )\n",
    "        outliers_iqr += [\n",
    "            data[data[var] > top].count()[var] + data[data[var] < bottom].count()[var]\n",
    "        ]\n",
    "\n",
    "    return {\"iqr\": outliers_iqr, \"stdev\": outliers_stdev}\n",
    "\n",
    "\n",
    "if [] != numeric:\n",
    "    outliers: dict[str, int] = count_outliers(data, numeric)\n",
    "    figure(figsize=(12, HEIGHT))\n",
    "    plot_multibar_chart(\n",
    "        numeric,\n",
    "        outliers,\n",
    "        title=\"Nr of standard outliers per variable\",\n",
    "        xlabel=\"variables\",\n",
    "        ylabel=\"nr outliers\",\n",
    "        percentage=False,\n",
    "    )\n",
    "    #savefig(f\"images/{file_tag}_outliers_standard.png\")\n",
    "    show()\n",
    "else:\n",
    "    print(\"There are no numeric variables.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from library.dslabs_functions import set_chart_labels\n",
    "\n",
    "if [] != numeric:\n",
    "    fig, axs = subplots(\n",
    "        rows, cols, figsize=(cols * HEIGHT, rows * HEIGHT), squeeze=False\n",
    "    )\n",
    "    i: int\n",
    "    j: int\n",
    "    i, j = 0, 0\n",
    "    for n in range(len(numeric)):\n",
    "        set_chart_labels(\n",
    "            axs[i, j],\n",
    "            title=f\"Histogram for {numeric[n]}\",\n",
    "            xlabel=numeric[n],\n",
    "            ylabel=\"nr records\",\n",
    "        )\n",
    "        axs[i, j].hist(data[numeric[n]].dropna().values, \"auto\")\n",
    "        i, j = (i + 1, 0) if (n + 1) % cols == 0 else (i, j + 1)\n",
    "    #savefig(f\"images/{file_tag}_single_histograms_numeric.png\")\n",
    "    show()\n",
    "else:\n",
    "    print(\"There are no numeric variables.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from library.dslabs_functions import set_chart_labels\n",
    "from numpy import log\n",
    "from pandas import Series\n",
    "from scipy.stats import norm, expon, lognorm\n",
    "from matplotlib.axes import Axes\n",
    "from library.dslabs_functions import plot_multiline_chart\n",
    "\n",
    "\n",
    "def compute_known_distributions(x_values: list) -> dict:\n",
    "    distributions = dict()\n",
    "    # Gaussian\n",
    "    mean, sigma = norm.fit(x_values)\n",
    "    distributions[\"Normal(%.1f,%.2f)\" % (mean, sigma)] = norm.pdf(x_values, mean, sigma)\n",
    "    # Exponential\n",
    "    loc, scale = expon.fit(x_values)\n",
    "    distributions[\"Exp(%.2f)\" % (1 / scale)] = expon.pdf(x_values, loc, scale)\n",
    "    # LogNorm\n",
    "    sigma, loc, scale = lognorm.fit(x_values)\n",
    "    distributions[\"LogNor(%.1f,%.2f)\" % (log(scale), sigma)] = lognorm.pdf(\n",
    "        x_values, sigma, loc, scale\n",
    "    )\n",
    "    return distributions\n",
    "\n",
    "\n",
    "def histogram_with_distributions(ax: Axes, series: Series, var: str):\n",
    "    values: list = series.sort_values().to_list()\n",
    "    ax.hist(values, 20, density=True)\n",
    "    distributions: dict = compute_known_distributions(values)\n",
    "    plot_multiline_chart(\n",
    "        values,\n",
    "        distributions,\n",
    "        ax=ax,\n",
    "        title=\"Best fit for %s\" % var,\n",
    "        xlabel=var,\n",
    "        ylabel=\"\",\n",
    "    )\n",
    "\n",
    "\n",
    "if [] != numeric:\n",
    "    fig, axs = subplots(\n",
    "        rows, cols, figsize=(cols * HEIGHT, rows * HEIGHT), squeeze=False\n",
    "    )\n",
    "    i, j = 0, 0\n",
    "    for n in range(len(numeric)):\n",
    "        histogram_with_distributions(axs[i, j], data[numeric[n]].dropna(), numeric[n])\n",
    "        i, j = (i + 1, 0) if (n + 1) % cols == 0 else (i, j + 1)\n",
    "    #savefig(f\"images/{file_tag}_histogram_numeric_distribution.png\")\n",
    "    show()\n",
    "else:\n",
    "    print(\"There are no numeric variables.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Series\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib.pyplot import savefig, show, subplots\n",
    "from library.dslabs_functions import define_grid, HEIGHT\n",
    "\n",
    "target = \"CovidPos\"\n",
    "\n",
    "values: Series = data[target].value_counts()\n",
    "\n",
    "figure(figsize=(4, 2))\n",
    "plot_bar_chart(\n",
    "    values.index.to_list(),\n",
    "    values.to_list(),\n",
    "    title=f\"Target distribution (target={target})\",\n",
    ")\n",
    "#savefig(f\"images/{file_tag}_class_distribution.png\")\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Sparcity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from library.dslabs_functions import HEIGHT, plot_multi_scatters_chart\n",
    "\n",
    "data = data.dropna()\n",
    "vars: list = data.columns.to_list()\n",
    "if [] != vars:\n",
    "    target = \"stroke\"\n",
    "    n: int = len(vars) - 1\n",
    "    fig: Figure\n",
    "    axs: ndarray\n",
    "    fig, axs = subplots(n, n, figsize=(n * HEIGHT, n * HEIGHT), squeeze=False)\n",
    "    for i in range(len(vars)):\n",
    "        var1: str = vars[i]\n",
    "        for j in range(i + 1, len(vars)):\n",
    "            var2: str = vars[j]\n",
    "            plot_multi_scatters_chart(data, var1, var2, ax=axs[i, j - 1])\n",
    "    #savefig(f\"images/{file_tag}_sparsity_study.png\")\n",
    "    show()\n",
    "else:\n",
    "    print(\"Sparsity class: there are no variables.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if [] != vars:\n",
    "    target = \"stroke\"\n",
    "\n",
    "    n: int = len(vars) - 1\n",
    "    fig, axs = subplots(n, n, figsize=(n * HEIGHT, n * HEIGHT), squeeze=False)\n",
    "    for i in range(len(vars)):\n",
    "        var1: str = vars[i]\n",
    "        for j in range(i + 1, len(vars)):\n",
    "            var2: str = vars[j]\n",
    "            plot_multi_scatters_chart(data, var1, var2, target, ax=axs[i, j - 1])\n",
    "    #savefig(f\"images/{file_tag}_sparsity_per_class_study.png\")\n",
    "    show()\n",
    "else:\n",
    "    print(\"Sparsity per class: there are no variables.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seaborn import heatmap\n",
    "from library.dslabs_functions import get_variable_types\n",
    "\n",
    "variables_types: dict[str, list] = get_variable_types(data)\n",
    "numeric: list[str] = variables_types[\"numeric\"]\n",
    "corr_mtx: DataFrame = data[numeric].corr().abs()\n",
    "\n",
    "figure()\n",
    "heatmap(\n",
    "    abs(corr_mtx),\n",
    "    xticklabels=numeric,\n",
    "    yticklabels=numeric,\n",
    "    annot=False,\n",
    "    cmap=\"Blues\",\n",
    "    vmin=0,\n",
    "    vmax=1,\n",
    ")\n",
    "#savefig(f\"images/{file_tag}_correlation_analysis.png\")\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Granularity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import radians, sin, cos, sqrt, atan2\n",
    "\n",
    "# Define the latitude and longitude for each state\n",
    "state_coordinates = {\n",
    "    'Alabama': [32.318231, -86.902298],\n",
    "    'Alaska': [63.588753, -154.493062],\n",
    "    'Arizona': [34.048928, -111.093731],\n",
    "    'Arkansas': [35.20105, -91.831833],\n",
    "    'California': [36.778261, -119.417932],\n",
    "    'Colorado': [39.550051, -105.782067],\n",
    "    'Connecticut': [41.603221, -73.087749],\n",
    "    'Delaware': [38.910832, -75.52767],\n",
    "    'District of Columbia': [38.895, -77.03667],\n",
    "    'Florida': [27.664827, -81.515754],\n",
    "    'Georgia': [32.157435, -82.907123],\n",
    "    'Hawaii': [19.898682, -155.665857],\n",
    "    'Idaho': [44.068202, -114.742041],\n",
    "    'Illinois': [40.633125, -89.398528],\n",
    "    'Indiana': [40.551217, -85.602364],\n",
    "    'Iowa': [41.878003, -93.097702],\n",
    "    'Kansas': [39.011902, -98.484246],\n",
    "    'Kentucky': [37.839333, -84.270018],\n",
    "    'Louisiana': [31.244823, -92.145024],\n",
    "    'Maine': [45.253783, -69.445469],\n",
    "    'Maryland': [39.045755, -76.641271],\n",
    "    'Massachusetts': [42.407211, -71.382437],\n",
    "    'Michigan': [44.314844, -85.602364],\n",
    "    'Minnesota': [46.729553, -94.6859],\n",
    "    'Mississippi': [32.354668, -89.398528],\n",
    "    'Missouri': [37.964253, -91.831833],\n",
    "    'Montana': [46.879682, -110.362566],\n",
    "    'Nebraska': [41.492537, -99.901813],\n",
    "    'Nevada': [38.80261, -116.419389],\n",
    "    'New Hampshire': [43.193852, -71.572395],\n",
    "    'New Jersey': [40.058324, -74.405661],\n",
    "    'New Mexico': [34.97273, -105.032363],\n",
    "    'New York': [43.299428, -74.217933],\n",
    "    'North Carolina': [35.759573, -79.0193],\n",
    "    'North Dakota': [47.551493, -101.002012],\n",
    "    'Ohio': [40.417287, -82.907123],\n",
    "    'Oklahoma': [35.007752, -97.092877],\n",
    "    'Oregon': [43.804133, -120.554201],\n",
    "    'Pennsylvania': [41.203322, -77.194525],\n",
    "    'Rhode Island': [41.580095, -71.477429],\n",
    "    'South Carolina': [33.836081, -81.163725],\n",
    "    'South Dakota': [43.969515, -99.901813],\n",
    "    'Tennessee': [35.517491, -86.580447],\n",
    "    'Texas': [31.968599, -99.901813],\n",
    "    'Utah': [39.32098, -111.093731],\n",
    "    'Vermont': [44.558803, -72.577841],\n",
    "    'Virginia': [37.431573, -78.656894],\n",
    "    'Washington': [47.751074, -120.740139],\n",
    "    'West Virginia': [38.597626, -80.454903],\n",
    "    'Wisconsin': [43.78444, -88.787868],\n",
    "    'Wyoming': [43.075968, -107.290284],\n",
    "    'Guam': [13.444304, 144.793732],\n",
    "    'Puerto Rico': [18.220833, -66.590149],\n",
    "    'Virgin Islands': [18.3434, -64.8672]\n",
    "}\n",
    "\n",
    "# Convert the dictionary into a DataFrame\n",
    "df_state = pd.DataFrame.from_dict(state_coordinates, orient='index', columns=['latitude', 'longitude'])\n",
    "# Convert the dictionary into a DataFrame\n",
    "df_state = pd.DataFrame.from_dict(state_coordinates, orient='index', columns=['latitude', 'longitude'])\n",
    "\n",
    "# Calculate the median latitude and longitude\n",
    "median_latitude = df_state['latitude'].median()\n",
    "median_longitude = df_state['longitude'].median()\n",
    "\n",
    "# Create a new column 'quadrant' based on the median latitude and longitude\n",
    "df_state['Quadrant'] = np.select(\n",
    "    [\n",
    "        (df_state['latitude'] > median_latitude) & (df_state['longitude'] > median_longitude), \n",
    "        (df_state['latitude'] <= median_latitude) & (df_state['longitude'] > median_longitude),\n",
    "        (df_state['latitude'] > median_latitude) & (df_state['longitude'] <= median_longitude),\n",
    "        (df_state['latitude'] <= median_latitude) & (df_state['longitude'] <= median_longitude)\n",
    "    ], \n",
    "    [\n",
    "        'Q1', \n",
    "        'Q2',\n",
    "        'Q3',\n",
    "        'Q4'\n",
    "    ], \n",
    "    default='Unknown'\n",
    ")\n",
    "\n",
    "# Assuming df is your DataFrame and it has a column 'quadrant'\n",
    "df_state['Quadrant'] = df_state['Quadrant'].map({'Q1': 0, 'Q2': 1, 'Q3': 2, 'Q4': 3})\n",
    "df = pd.merge(data, df_state, left_on='State', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import ndarray\n",
    "\n",
    "def analyse_property_granularity(\n",
    "    data: DataFrame, property: str, vars: list[str]\n",
    ") -> ndarray:\n",
    "    cols: int = len(vars)\n",
    "    fig: Figure\n",
    "    axs: ndarray\n",
    "    fig, axs = subplots(1, cols, figsize=(cols * HEIGHT, HEIGHT), squeeze=False)\n",
    "    fig.suptitle(f\"Granularity study for {property}\")\n",
    "    for i in range(cols):\n",
    "        counts: Series[int] = data[vars[i]].value_counts()\n",
    "        plot_bar_chart(\n",
    "            counts.index.to_list(),\n",
    "            counts.to_list(),\n",
    "            ax=axs[0, i],\n",
    "            title=vars[i],\n",
    "            xlabel=vars[i],\n",
    "            ylabel=\"nr records\",\n",
    "            percentage=False,\n",
    "        )\n",
    "    return axs\n",
    "analyse_property_granularity(df, \"State\", [\"State\",\"Quadrant\"])\n",
    "show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
